{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d352f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# WRITE A FUNCTION THAT LOADS THE FILES \n",
    "# THEN PLOT THE WINDOWS ETC. CALCULATE STATS, BASED ON WHITEBOARD\n",
    "# WRITE OUT A GOOD DESCRIPTION OF WHAT ALL THE KEYS IN THE DATA TABLE ARE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3007ea9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e79127d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#datadir = '/Users/paddyslator/OneDrive - University College London/data/PD DRUM'\n",
    "\n",
    "cohort = 'PD'\n",
    "\n",
    "if cohort=='PD':\n",
    "    datadir = r\"C:\\Users\\Paula\\Documents\\drum-hackathon\\data\\raw\\PD DRUM\"\n",
    "    figdir =  r\"C:\\Users\\Paula\\Documents\\drum-hackathon\\data\\raw\\PD_figures\"\n",
    "\n",
    "    file_wildcard = \"*hd-output-device*.csv\"\n",
    "\n",
    "if cohort =='HD':\n",
    "    datadir = \"/Users/scmps8/Library/CloudStorage/OneDrive-CardiffUniversity/data/drum/HD_DRUM\"\n",
    "    figdir =  \"/Users/scmps8/Library/CloudStorage/OneDrive-CardiffUniversity/data/drum/HD_figures\"\n",
    "    \n",
    "    file_wildcard = \"hddrum_*/*hd-output-device*.csv\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43302c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get list of participant directories \n",
    "participant_paths = glob.glob(os.path.join(datadir,'*'))\n",
    "\n",
    "# Initialize lists for participants with hd drum session files\n",
    "participants = []\n",
    "\n",
    "# Check each participant directory for session files\n",
    "for participant_path in participant_paths:\n",
    "    participant = os.path.basename(participant_path)\n",
    "    \n",
    "    # Define the path pattern for session files for this participant\n",
    "    session_paths = glob.glob(os.path.join(datadir, participant, file_wildcard))\n",
    "    \n",
    "    if session_paths:  # If there are any session files\n",
    "        participants.append(participant)\n",
    "\n",
    "\n",
    "# Filter participant paths to include only those with session files\n",
    "participant_paths = [path for path in participant_paths if os.path.basename(path) in participants]\n",
    "\n",
    "# Check if we need to print or use valid_participants or filtered_participant_paths\n",
    "print(\"Valid Participants:\", participants)\n",
    "print(\"Filtered Participant Paths:\", participant_paths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e85086-4f2e-441b-9513-68b033ed5bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "participants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852ded80-90ec-46d1-a7e7-25bfeb014069",
   "metadata": {},
   "outputs": [],
   "source": [
    "#functions that get the session number, track number etc.\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import io\n",
    "\n",
    "def extract_track_number(text):\n",
    "    pattern = r'track-(\\d+)'\n",
    "    match = re.search(pattern, text)\n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "    else:\n",
    "        return None  # or handle the case when no match is found\n",
    "        \n",
    "def extract_session_number(filename):\n",
    "    pattern = r'session-(\\d+)-track'\n",
    "    match = re.search(pattern, filename)\n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "    return None\n",
    "\n",
    "\n",
    "# #function for reading the csv files while dealing with the metadata\n",
    "# def read_csv_with_metadata(csv_file):\n",
    "#     metadata = {}\n",
    "#     data_lines = []\n",
    "\n",
    "#     with open(csv_file, 'r') as f:\n",
    "#         lines = f.readlines()\n",
    "\n",
    "#         # Read metadata\n",
    "#         for line in lines[:25]:  # assuming metadata is in the first 25 lines\n",
    "#             if line.strip():  # ignore empty lines\n",
    "#                 key, value = line.strip().split(',', 1)\n",
    "#                 metadata[key.strip()] = value.strip()\n",
    "\n",
    "#         # Read data table\n",
    "#         start_idx = 27  # assuming data table starts from line 27\n",
    "#         data_lines = lines[start_idx:]\n",
    "\n",
    "#     # Create DataFrame for data table\n",
    "#     data_table = pd.read_csv(io.StringIO(''.join(data_lines)))\n",
    "\n",
    "#     return metadata, data_table\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import io\n",
    "\n",
    "def read_csv_with_metadata(csv_file, required_metadata_keys):\n",
    "    \"\"\"\n",
    "    Reads the CSV file, checks if it contains the required metadata,\n",
    "    and returns the metadata and data table if valid.\n",
    "    \"\"\"\n",
    "    metadata = {}\n",
    "    data_lines = []\n",
    "\n",
    "    try:\n",
    "        with open(csv_file, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "\n",
    "            # Read metadata\n",
    "            for line in lines[:25]:  # assuming metadata is in the first 25 lines\n",
    "                if line.strip():  # ignore empty lines\n",
    "                    try:\n",
    "                        key, value = line.strip().split(',', 1)\n",
    "                        metadata[key.strip()] = value.strip()\n",
    "                    except ValueError:\n",
    "                        # Skip lines that don't contain metadata in the expected format\n",
    "                        continue\n",
    "\n",
    "            # Validate metadata\n",
    "            if not all(key in metadata for key in required_metadata_keys):\n",
    "                print(f\"Required metadata missing in file {csv_file}\")\n",
    "                return None, None  # Return None if required metadata is missing\n",
    "\n",
    "            # Read data table\n",
    "            start_idx = 27  # assuming data table starts from line 27\n",
    "            data_lines = lines[start_idx:]\n",
    "\n",
    "            # Create DataFrame for data table\n",
    "            data_table = pd.read_csv(io.StringIO(''.join(data_lines)))\n",
    "\n",
    "            return metadata, data_table\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading file {csv_file}: {e}\")\n",
    "        return None, None  # Return None if there is an error\n",
    "\n",
    "\n",
    "def read_csv_with_metadata_tap(csv_file, required_metadata_keys):\n",
    "    \"\"\"\n",
    "    Reads the CSV file, checks if it contains the required metadata,\n",
    "    and returns the metadata and data table if valid.\n",
    "    \"\"\"\n",
    "    metadata = {}\n",
    "    data_lines = []\n",
    "\n",
    "    try:\n",
    "        with open(csv_file, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "\n",
    "            # Read metadata\n",
    "            for line in lines[:25]:  # assuming metadata is in the first 25 lines\n",
    "                if line.strip():  # ignore empty lines\n",
    "                    try:\n",
    "                        key, value = line.strip().split(',', 1)\n",
    "                        metadata[key.strip()] = value.strip()\n",
    "                    except ValueError:\n",
    "                        # Skip lines that don't contain metadata in the expected format\n",
    "                        continue\n",
    "\n",
    "            # Validate metadata\n",
    "            if not all(key in metadata for key in required_metadata_keys):\n",
    "                print(f\"Required metadata missing in file {csv_file}\")\n",
    "                return None, None  # Return None if required metadata is missing\n",
    "\n",
    "            # Read data table\n",
    "            start_idx = 27  # assuming data table starts from line 27\n",
    "            data_lines = lines[start_idx:]\n",
    "\n",
    "            # Create DataFrame for data table\n",
    "            data_table = pd.read_csv(io.StringIO(''.join(data_lines)))\n",
    "\n",
    "            left_double_taps, right_double_taps = hit_timestamps(data_table)\n",
    "            wrong_presses = 0\n",
    "            wrong_presses += misses_counter(data_table)\n",
    "\n",
    "            return metadata, data_table, left_double_taps, right_double_taps, wrong_presses\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading file {csv_file}: {e}\")\n",
    "        return None, None  # Return None if there is an error\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Function to filter out files starting with \"~$\" (temp office files)\n",
    "def is_valid_file(file_path):\n",
    "    return not os.path.basename(file_path).startswith('~$')\n",
    "\n",
    "#function to clean trailing commas from metadata\n",
    "def clean_metadata(metadata):\n",
    "    # Define the fields that should not be converted\n",
    "    non_convertible_fields = {\n",
    "        'User Id', 'Date', 'Time', 'Session', 'Track', \n",
    "        'Track File', 'Metadata File'\n",
    "    }\n",
    "    \n",
    "    cleaned_metadata = {}\n",
    "\n",
    "    for key, value in metadata.items():\n",
    "        if isinstance(value, dict):  # If the value is a nested dictionary, clean it recursively\n",
    "            cleaned_value = clean_metadata(value)\n",
    "        else:\n",
    "            # Remove trailing commas and whitespace\n",
    "            cleaned_value = value.rstrip(', ')\n",
    "            \n",
    "            # Convert to float if not in non_convertible_fields\n",
    "            if key not in non_convertible_fields:\n",
    "                try:\n",
    "                    cleaned_value = float(cleaned_value)\n",
    "                except ValueError:\n",
    "                    print(f\"Could not convert {key}: {cleaned_value} to float\")\n",
    "        \n",
    "        # Update the cleaned_metadata dictionary\n",
    "        cleaned_metadata[key] = cleaned_value\n",
    "\n",
    "    return cleaned_metadata\n",
    "\n",
    "\n",
    "import re\n",
    "\n",
    "# def clean_metadata(metadata):\n",
    "#     cleaned_metadata = {}\n",
    "    \n",
    "#     for key, value in metadata.items():\n",
    "#         # Check if the value is a string and has extra commas\n",
    "#         if isinstance(value, str):\n",
    "#             # Remove extra commas and attempt to extract the primary value\n",
    "#             value = re.sub(r',+', ',', value)  # Replace multiple commas with a single comma\n",
    "#             parts = value.split(',')\n",
    "            \n",
    "#             # Take the first part as the cleaned value if it is a valid float\n",
    "#             try:\n",
    "#                 primary_value = float(parts[0])\n",
    "#             except ValueError:\n",
    "#                 print(f\"Could not convert {key}: {value} to float\")\n",
    "#                 primary_value = None\n",
    "            \n",
    "#             cleaned_metadata[key] = primary_value\n",
    "#         else:\n",
    "#             # If the value is not a string, just add it as is\n",
    "#             cleaned_metadata[key] = value\n",
    "    \n",
    "#     return cleaned_metadata\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# def convert_metadata_values(metadata):\n",
    "#     # Define the fields that should not be converted\n",
    "#     non_convertible_fields = {\n",
    "#         'User Id', 'Date', 'Time', 'Session', 'Track', \n",
    "#         'Track File', 'Metadata File'\n",
    "#     }\n",
    "\n",
    "#     # Iterate over the metadata dictionary\n",
    "#     for key in metadata:\n",
    "#         print(key)\n",
    "#         for subkey in key:\n",
    "#             if subkey not in non_convertible_fields:\n",
    "#                 try:\n",
    "#                     # Attempt to convert the value to a float\n",
    "#                     metadata[key][subkey] = float(metadata[key][subkey])\n",
    "#                 except ValueError:\n",
    "#                     # If conversion fails, print an error message\n",
    "#                     print(f\"Could not convert {key}: {metadata[key][subkey]} to float\")\n",
    "    \n",
    "#     return metadata\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec5b0ef-0730-4495-896d-5c2a5ab1ae85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# thing = os.path.join(datadir,'140223-701/hddrum_58c8dfe9c10843d8/uoc01991-hd-output-device-58c8dfe9c10843d8-session-19-track-0-2023-04-12-21-21-35.csv')\n",
    "\n",
    "# this_session_metadata, this_session_data_table = read_csv_with_metadata(thing, required_metadata_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7849cf-9555-4393-bf17-df08f48ec1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defined the required metadata keys\n",
    "\n",
    "# required_metadata_keys = [\n",
    "#     'User Id', 'Date', 'Time', 'Session', 'Track', 'Track File', 'Metadata File',\n",
    "#     'Track Duration(s)', 'Total Engagement Time(s)', 'Total Drum hits in track',\n",
    "#     'Timing Window (ms)', 'Successful Drum hits', 'Success Accuracy Threshold (%)',\n",
    "#     'Average Hit Accuracy (%)', 'Average Reaction Time (ms)', 'Average Left Reaction time (ms)',\n",
    "#     'Average Right Reaction time (ms)', 'Best Left Reaction time (ms)', 'Best Right Reaction time (ms)',\n",
    "#     'Left Accuracy (%)', 'Right Accuracy (%)', 'Left Hit Score', 'Right Hit Score'\n",
    "# ]\n",
    "\n",
    "required_metadata_keys = ['User Id', 'Date', 'Time']\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff66f8d5-275a-47d4-947f-1ecb88509d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = defaultdict(dict)\n",
    "fulldata_table = defaultdict(dict)\n",
    "\n",
    "#Initialize empty list to hold the dictionary\n",
    "list_of_entries = []\n",
    "\n",
    "\n",
    "for participant in participants:\n",
    "    print(f\"Processing participant: {participant}\")\n",
    "    \n",
    "    # Get the file paths to the session CSV files\n",
    "    session_paths = glob.glob(os.path.join(datadir, participant, file_wildcard))\n",
    "    \n",
    "    # Filter out files starting with \"~$\"\n",
    "    session_paths = [path for path in session_paths if is_valid_file(path)]\n",
    "    \n",
    "    # Order them so that the files are in the order they were attempted\n",
    "    session_paths = sorted(session_paths)\n",
    "    \n",
    "    # Dictionary to track attempt numbers for each session\n",
    "    session_attempt_counter = defaultdict(int)\n",
    "    \n",
    "    for session in session_paths:\n",
    "        this_session_number = extract_session_number(session)\n",
    "        \n",
    "        # Increment the attempt number for this session\n",
    "        session_attempt_counter[this_session_number] += 1\n",
    "        this_attempt_number = session_attempt_counter[this_session_number]\n",
    "\n",
    "\n",
    "        try:\n",
    "            # Read metadata and data table\n",
    "            this_session_metadata, this_session_data_table = read_csv_with_metadata(session, required_metadata_keys)\n",
    "            this_session_metadata_double, this_session_data_table_double, this_session_left_double_taps, this_session_right_double_taps, this_session_wrong_presses = read_csv_with_metadata_tap(session, required_metadata_keys)\n",
    "\n",
    "\n",
    "            # Store metadata and data table\n",
    "            metadata[(participant,this_session_number,this_attempt_number)] = this_session_metadata\n",
    "            fulldata_table[(participant, this_session_number, this_attempt_number)] = this_session_data_table\n",
    "            print(f\"Processed participant: {participant}, session: {this_session_number}, attempt: {this_attempt_number}\")\n",
    "            list_of_entries.append([participant, this_session_number, this_attempt_number, this_session_left_double_taps, this_session_right_double_taps, this_session_wrong_presses])\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {session}: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51dddf67-6ccc-4bef-bc90-7bb214540d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove keys with None values directly\n",
    "keys_to_remove = [k for k, v in metadata.items() if v is None]\n",
    "\n",
    "for key in keys_to_remove:\n",
    "    del metadata[key]\n",
    "\n",
    "\n",
    "#clean metadata\n",
    "metadata = clean_metadata(metadata)\n",
    "\n",
    "#convert numbers in metadata to float\n",
    "#metadata = convert_metadata_values(metadata)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200e179c-3264-41ed-b670-b812866fb244",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print metadata and data table\n",
    "# print(\"Metadata:\")\n",
    "# for participant, sessions in metadata.items():\n",
    "#     print(f\"Participant: {participant}\")\n",
    "#     for session_number, metadata_info in sessions.items():\n",
    "#         print(f\"Session {session_number}: {metadata_info}\")\n",
    "\n",
    "print(\"\\nFull Data Table:\")\n",
    "for key, data_table in fulldata_table.items():\n",
    "    participant, session_number, attempt_number = key\n",
    "    print(f\"Participant: {participant}, Session {session_number}, Attempt {attempt_number}\")\n",
    "    print(data_table.head())  # assuming you want to print the first few rows of each data table\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4e7495-a0df-42e7-aadf-0f82bfdb7bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "participants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155de93f-baa9-4ceb-b218-06158c0604db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# Number of subplots\n",
    "num_plots = len(participants)\n",
    "\n",
    "# Determine the size of the subplot grid (square-ish)\n",
    "grid_size = int(math.ceil(math.sqrt(num_plots)))\n",
    "\n",
    "# Create subplots\n",
    "fig, axes = plt.subplots(grid_size, grid_size, figsize=(30, 30))\n",
    "\n",
    "# Flatten axes array for easy iteration\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Determine consistent axis limits\n",
    "all_sessions = set()\n",
    "all_attempts = []\n",
    "\n",
    "# First pass: find the range of sessions and attempts\n",
    "for participant in participants:\n",
    "    # Filter metadata for the current participant\n",
    "    participant_metadata = {key: value for key, value in metadata.items() if key[0] == participant}\n",
    "    \n",
    "    if participant_metadata:\n",
    "        sessions = sorted(set(key[1] for key in participant_metadata.keys()))\n",
    "        attempts_per_session = [0] * len(sessions)\n",
    "        \n",
    "        for (participant_id, session, attempt), _ in participant_metadata.items():\n",
    "            session_index = sessions.index(session)\n",
    "            attempts_per_session[session_index] += 1\n",
    "        \n",
    "        all_sessions.update(sessions)\n",
    "        all_attempts.extend(attempts_per_session)\n",
    "\n",
    "# Convert to sorted lists\n",
    "all_sessions = sorted(all_sessions)\n",
    "max_attempts = max(all_attempts, default=0)\n",
    "\n",
    "# Second pass: plot data with consistent axis ticks\n",
    "for i, participant in enumerate(participants):\n",
    "    # Filter metadata for the current participant\n",
    "    participant_metadata = {key: value for key, value in metadata.items() if key[0] == participant}\n",
    "    \n",
    "    if not participant_metadata:\n",
    "        # If no metadata for the participant, skip this subplot\n",
    "        axes[i].axis('off')\n",
    "        continue\n",
    "    \n",
    "    # Aggregate number of attempts per session\n",
    "    sessions = sorted(set(key[1] for key in participant_metadata.keys()))\n",
    "    attempts_per_session = [0] * len(sessions)\n",
    "    \n",
    "    for (participant_id, session, attempt), _ in participant_metadata.items():\n",
    "        session_index = sessions.index(session)\n",
    "        attempts_per_session[session_index] += 1\n",
    "    \n",
    "    # Plot on the corresponding subplot\n",
    "    ax = axes[i]\n",
    "    ax.bar(sessions, attempts_per_session, color='skyblue')\n",
    "    ax.set_title(participant[:8])  # Display only the first 5 characters\n",
    "    ax.set_xlabel('Session Number')\n",
    "    ax.set_ylabel('Number of Attempts')\n",
    "    ax.set_xticks(all_sessions)  # Set x-axis ticks\n",
    "    ax.set_xticks(np.arange(min(all_sessions), max(all_sessions) + 1, 1))  # Ensure ticks are integers\n",
    "    ax.set_yticks(np.arange(0, max_attempts + 1, 1))  # Ensure y-axis ticks are integers\n",
    "    ax.tick_params(axis='x', rotation=90)  # Rotate x-axis ticks by 45 degrees\n",
    "\n",
    "    #squash down the attemps a bit\n",
    "    #ax.set_ylim((0, 20))  # Ensure y-axis ticks are integers\n",
    "\n",
    "    \n",
    "# Hide any unused subplots\n",
    "for j in range(num_plots, len(axes)):\n",
    "    axes[j].axis('off')\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(os.path.join(figdir,'attempts_per_session_by_participant.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3e58b5-006d-4389-aa7c-ddf152faddf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Prepare data structure for storing average hit rates\n",
    "avg_hit_rates = {}\n",
    "\n",
    "# Compute average hit rates for each participant and session\n",
    "for participant in participants:\n",
    "    # Filter metadata for the current participant\n",
    "    participant_metadata = {key: value for key, value in metadata.items() if key[0] == participant}\n",
    "    \n",
    "    # Initialize data structure for storing session hit rates\n",
    "    session_hit_rates = {}\n",
    "\n",
    "    print(participant)    \n",
    "    \n",
    "    for (pid, session, attempt), meta in participant_metadata.items():            \n",
    "        # Get the hit accuracy\n",
    "        # left_accuracy = float(meta.get('Left Accuracy (%)', 0))\n",
    "        # right_accuracy = float(meta.get('Right Accuracy (%)', 0))\n",
    "        # Get the hit accuracy    \n",
    "        hit_accuracy = float(meta.get('Average Hit Accuracy (%)', 0))\n",
    "              \n",
    "        if session not in session_hit_rates:\n",
    "            session_hit_rates[session] = []\n",
    "            \n",
    "        session_hit_rates[session].append(hit_accuracy)\n",
    "    \n",
    "    # Calculate average hit rate for each session\n",
    "    avg_hit_rates[participant] = {session: np.mean(hit_rates) for session, hit_rates in session_hit_rates.items()}\n",
    "\n",
    "# Number of participants\n",
    "num_participants = len(avg_hit_rates)\n",
    "\n",
    "# Determine the size of the subplot grid (square-ish)\n",
    "grid_size = int(np.ceil(np.sqrt(num_participants)))\n",
    "\n",
    "# Create subplots\n",
    "fig, axes = plt.subplots(grid_size, grid_size, figsize=(30, 30))\n",
    "axes = axes.flatten()  # Flatten axes array for easy iteration\n",
    "\n",
    "# Determine the overall range for x and y axes\n",
    "all_sessions = set()\n",
    "all_accuracies = []\n",
    "\n",
    "for hit_rates in avg_hit_rates.values():\n",
    "    all_sessions.update(hit_rates.keys())\n",
    "    all_accuracies.extend(hit_rates.values())\n",
    "\n",
    "min_session, max_session = min(all_sessions), max(all_sessions)\n",
    "min_accuracy, max_accuracy = min(all_accuracies), max(all_accuracies)\n",
    "\n",
    "# Plotting each participant's average hit rate\n",
    "for i, (participant, hit_rates) in enumerate(avg_hit_rates.items()):\n",
    "    ax = axes[i]\n",
    "    sessions = list(hit_rates.keys())\n",
    "    accuracies = [hit_rates[session] for session in sessions]\n",
    "    \n",
    "    ax.bar(sessions, accuracies, color='blue', alpha=0.7)\n",
    "    ax.set_title(participant[:8])  # Display only the first 5 characters of participant IDs\n",
    "    ax.set_xlabel('Session Number')\n",
    "    ax.set_ylabel('Average Hit Rate (%)')\n",
    "    \n",
    "    # Set consistent x and y axis ticks\n",
    "    ax.set_xticks(np.arange(min_session, max_session + 1))\n",
    "    ax.set_yticks(np.arange(0, max_accuracy + 1, step=10))\n",
    "    ax.set_xlim(min_session - 0.5, max_session + 0.5)  # Adjust x limits to fit bars better\n",
    "    ax.set_ylim(0, max_accuracy + 5)  # Adjust y limits to fit the bars and avoid clipping\n",
    "    ax.tick_params(axis='x', rotation=90)  # Rotate x-axis ticks by 45 degrees\n",
    "\n",
    "# Hide any unused subplots\n",
    "for j in range(num_participants, len(axes)):\n",
    "    axes[j].axis('off')\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(os.path.join(figdir,'average_hit_rate_by_participant.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22892c30-b989-470f-a61b-0853d2e8bf97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "# Find maximum session number\n",
    "max_sessions = max([key[1] for key in metadata.keys()])\n",
    "\n",
    "# Find overall maximum attempt number\n",
    "overall_max_attempts = max([key[2] for key in metadata.keys()])\n",
    "\n",
    "# Create subplots\n",
    "fig, axs = plt.subplots(max_sessions + 1, 1, figsize=(10, 70))\n",
    "\n",
    "# Define a colormap\n",
    "cmap = cm.get_cmap('tab20', len(participants))\n",
    "\n",
    "# Create a dictionary to store each participant's assigned color\n",
    "participant_colors = {participant: cmap(i) for i, participant in enumerate(participants)}\n",
    "\n",
    "# Store handles and labels for the legend\n",
    "handles, labels = [], []\n",
    "\n",
    "for session in range(max_sessions + 1):\n",
    "    # Collect data for all participants in this session\n",
    "    for participant in participants:\n",
    "        attempts = []\n",
    "        accuracies = []\n",
    "        \n",
    "        for attempt in range(1, overall_max_attempts + 1):\n",
    "            key = (participant, session, attempt)\n",
    "            if key in metadata:\n",
    "                attempts.append(attempt)\n",
    "                accuracies.append(float(metadata[key]['Average Hit Accuracy (%)']))\n",
    "        \n",
    "        if attempts:\n",
    "            # Plot joined lines for this participant with consistent color\n",
    "            participant_label = participant[:8]\n",
    "            color = participant_colors[participant]\n",
    "            line, = axs[session].plot(attempts, accuracies, 'o-', label=participant_label, color=color)\n",
    "            \n",
    "            # Collect handles and labels\n",
    "            if session == 0:  # Only collect labels from the first session to avoid duplicates\n",
    "                handles.append(line)\n",
    "                labels.append(participant_label)\n",
    "\n",
    "    # Set the title, labels, and x-axis limits\n",
    "    axs[session].set_title(f'Session {session}')\n",
    "    axs[session].set_xlabel('Attempt number')\n",
    "    axs[session].set_ylabel('Hit accuracy (%)')\n",
    "    #axs[session].set_xlim(0.9, overall_max_attempts)  # Set x-axis limits to ensure consistency\n",
    "    axs[session].set_xlim(0.9, 20)  # Set x-axis limits to ensure consistency\n",
    "    axs[session].set_xticks(range(1, 20))  # Set x-axis ticks\n",
    "    axs[session].set_ylim(0, 100)  # Set y-axis limits to ensure consistency\n",
    "    axs[session].tick_params(axis='x', rotation=90)  # Rotate x-axis ticks by 45 degrees\n",
    "\n",
    "    # Add a line with the progression percentage to each plot\n",
    "    progression_percentage = 70\n",
    "    axs[session].plot(np.linspace(0.9, overall_max_attempts, 100), np.tile(progression_percentage, (100, 1)), 'k--')\n",
    "\n",
    "# Create a single legend at the top\n",
    "fig.legend(handles, labels, loc='upper center', ncol=5, frameon=False, title='Participants')\n",
    "\n",
    "# Adjust layout to make space for the legend\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.97])  # Adjust rect to make space for the legend\n",
    "\n",
    "plt.savefig(os.path.join(figdir, 'attempt_accuracy_tracking_by_session_cutoff.png'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dee1ab1-8b65-4835-9c76-28cf9bcdbd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Simulated metadata dictionary for illustration purposes\n",
    "# metadata = {(participant, session, attempt): {...}, ...}\n",
    "\n",
    "# Extract the maximum session number\n",
    "max_sessions = max([key[1] for key in metadata.keys()])\n",
    "\n",
    "# Initialize a dictionary to hold the number of attempts per session\n",
    "session_attempts = {session: [] for session in range(max_sessions + 1)}\n",
    "\n",
    "# Populate the session_attempts dictionary\n",
    "for (participant, session, attempt) in metadata.keys():\n",
    "    session_attempts[session].append(attempt)\n",
    "\n",
    "# Calculate the average number of attempts for each session\n",
    "average_attempts_per_session = {session: np.mean(attempts) for session, attempts in session_attempts.items()}\n",
    "\n",
    "# Sort the session numbers\n",
    "sorted_sessions = sorted(average_attempts_per_session.keys())\n",
    "\n",
    "# Extract the corresponding average attempts\n",
    "sorted_average_attempts = [average_attempts_per_session[session] for session in sorted_sessions]\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(sorted_sessions, sorted_average_attempts, color='skyblue')\n",
    "plt.xlabel('Session Number')\n",
    "plt.ylabel('Average Number of Attempts')\n",
    "#plt.title('Average Number of Attempts per Session')\n",
    "\n",
    "# Set x-ticks to be integers\n",
    "plt.xticks(ticks=np.arange(min(sorted_sessions), max(sorted_sessions) + 1))\n",
    "\n",
    "plt.grid(axis='y')\n",
    "\n",
    "plt.savefig(os.path.join(figdir,'attempts_per_session_overall.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52301a3c-bcc0-4838-a2c4-eea9d1b4a556",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "# Simulated metadata dictionary for illustration purposes\n",
    "# metadata = {(participant, session, attempt): {...}, ...}\n",
    "\n",
    "# Extract participants and their sessions\n",
    "participants_sessions = {}\n",
    "\n",
    "for participant, session, attempt in metadata.keys():\n",
    "    if participant not in participants_sessions:\n",
    "        participants_sessions[participant] = []\n",
    "    participants_sessions[participant].append(session)\n",
    "\n",
    "# Determine the last session for each participant\n",
    "last_sessions = {participant: max(sessions) for participant, sessions in participants_sessions.items()}\n",
    "\n",
    "# Count the number of participants who failed at each session\n",
    "session_fail_counts = Counter(last_sessions.values())\n",
    "\n",
    "# Get all possible session numbers\n",
    "all_sessions = range(max(session_fail_counts.keys()) + 1)\n",
    "\n",
    "# Extract the count of failures for each session, filling in 0s for sessions with no failures\n",
    "fail_counts = [session_fail_counts.get(session, 0) for session in all_sessions]\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(all_sessions, fail_counts, color='skyblue')\n",
    "plt.xlabel('Session Number')\n",
    "plt.ylabel('Number of Participants who gave up')\n",
    "#plt.title('Number of Participants who Failed at Each Session')\n",
    "\n",
    "# Set x-ticks to be integers\n",
    "plt.xticks(ticks=np.arange(min(all_sessions), max(all_sessions) + 1))\n",
    "\n",
    "plt.grid(axis='y')\n",
    "\n",
    "plt.savefig(os.path.join(figdir,'give_up_per_session.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86fef154-c196-4191-9cc1-78ca97fa7316",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Simulated metadata dictionary for illustration purposes\n",
    "# metadata = {(participant, session, attempt): {...}, ...}\n",
    "\n",
    "# Extract the maximum session number\n",
    "max_sessions = max([key[1] for key in metadata.keys()])\n",
    "\n",
    "# Initialize a dictionary to hold the hit accuracies per session\n",
    "session_accuracies = {session: [] for session in range(max_sessions + 1)}\n",
    "\n",
    "# Populate the session_accuracies dictionary\n",
    "for (participant, session, attempt) in metadata.keys():\n",
    "    if 'Average Hit Accuracy (%)' in metadata[(participant, session, attempt)]:\n",
    "        accuracy = float(metadata[(participant, session, attempt)]['Average Hit Accuracy (%)'])\n",
    "        session_accuracies[session].append(accuracy)\n",
    "\n",
    "# Calculate the average hit accuracy for each session\n",
    "average_accuracy_per_session = {session: np.mean(accuracies) for session, accuracies in session_accuracies.items()}\n",
    "\n",
    "# Sort the session numbers\n",
    "sorted_sessions = sorted(average_accuracy_per_session.keys())\n",
    "\n",
    "# Extract the corresponding average accuracies\n",
    "sorted_average_accuracies = [average_accuracy_per_session[session] for session in sorted_sessions]\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars = plt.bar(sorted_sessions, sorted_average_accuracies, color='skyblue')\n",
    "plt.xlabel('Session Number', fontsize=14)\n",
    "plt.ylabel('Average Hit Accuracy (%)', fontsize=14)\n",
    "plt.title(cohort + ' participants', fontsize=14)\n",
    "\n",
    "# Set x-ticks to be integers\n",
    "plt.xticks(ticks=np.arange(min(sorted_sessions), max(sorted_sessions) + 1))\n",
    "\n",
    "plt.grid(axis='y')\n",
    "\n",
    "# Add an arrow pointing vertically upwards for session 6 with rotated text and fontsize 14\n",
    "session_number = 6\n",
    "if session_number in sorted_sessions:\n",
    "    index_of_session_6 = sorted_sessions.index(session_number)\n",
    "    bar_height = sorted_average_accuracies[index_of_session_6]\n",
    "    plt.annotate('off beat', \n",
    "                 xy=(session_number, bar_height),  # Arrow tip (session 6 bar)\n",
    "                 xytext=(session_number, bar_height + 10),  # Text position above the bar\n",
    "                 arrowprops=dict(facecolor='black', arrowstyle='->'),  # Arrow pointing upwards\n",
    "                 rotation=90,  # Rotate text 90 degrees to the left\n",
    "                 ha='center',  # Center horizontally\n",
    "                 va='bottom',  # Align text to the bottom vertically\n",
    "                 fontsize=14)  # Font size for the annotation\n",
    "\n",
    "# Save the plot\n",
    "plt.savefig(os.path.join(figdir, 'average_hit_accuracy_per_session.png'), bbox_inches='tight')\n",
    "plt.savefig(os.path.join(figdir, 'average_hit_accuracy_per_session.pdf'), bbox_inches='tight')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b618cd1-a721-46ec-95d2-6e50c3b5af37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Simulated metadata dictionary for illustration purposes\n",
    "# metadata = {(participant, session, attempt): {...}, ...}\n",
    "\n",
    "# Extract the maximum session number\n",
    "max_sessions = max([key[1] for key in metadata.keys()])\n",
    "\n",
    "# Initialize a dictionary to hold the hit accuracies per session\n",
    "session_accuracies = {session: [] for session in range(max_sessions + 1)}\n",
    "\n",
    "# Populate the session_accuracies dictionary\n",
    "for (participant, session, attempt) in metadata.keys():\n",
    "    if 'Average Hit Accuracy (%)' in metadata[(participant, session, attempt)]:\n",
    "        accuracy = float(metadata[(participant, session, attempt)]['Average Hit Accuracy (%)'])\n",
    "        session_accuracies[session].append(accuracy)\n",
    "\n",
    "# Calculate the average hit accuracy for each session\n",
    "average_accuracy_per_session = {session: np.mean(accuracies) for session, accuracies in session_accuracies.items()}\n",
    "\n",
    "# Sort the session numbers\n",
    "sorted_sessions = sorted(average_accuracy_per_session.keys())\n",
    "\n",
    "# Extract the corresponding average accuracies\n",
    "sorted_average_accuracies = [average_accuracy_per_session[session] for session in sorted_sessions]\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars = plt.bar(sorted_sessions, sorted_average_accuracies, color='skyblue')\n",
    "plt.xlabel('Session Number', fontsize=14)\n",
    "plt.ylabel('Average Hit Accuracy (%)', fontsize=14)\n",
    "plt.title(cohort + ' participants', fontsize=14)\n",
    "\n",
    "# Set x-ticks to be integers\n",
    "plt.xticks(ticks=np.arange(min(sorted_sessions), max(sorted_sessions) + 1))\n",
    "\n",
    "plt.grid(axis='y')\n",
    "\n",
    "# Add an arrow for session 6 with text \"off beat\"\n",
    "session_number = 6\n",
    "if session_number in sorted_sessions:\n",
    "    index_of_session_6 = sorted_sessions.index(session_number)\n",
    "    bar_height = sorted_average_accuracies[index_of_session_6]\n",
    "    plt.annotate('off beat', \n",
    "                 xy=(session_number, bar_height),  # Arrow tip (session 6 bar)\n",
    "                 xytext=(session_number, bar_height + 10),  # Text position above the bar\n",
    "                 arrowprops=dict(facecolor='black', arrowstyle='->'),  # Arrow pointing upwards\n",
    "                 rotation=90,  # Rotate text 90 degrees to the left\n",
    "                 ha='center',  # Center horizontally\n",
    "                 va='bottom',  # Align text to the bottom vertically\n",
    "                 fontsize=14)  # Font size for the annotation\n",
    "\n",
    "# Add an arrow for session 8 with text \"practise with both hands together\"\n",
    "session_number = 8\n",
    "if session_number in sorted_sessions:\n",
    "    index_of_session_8 = sorted_sessions.index(session_number)\n",
    "    bar_height = sorted_average_accuracies[index_of_session_8]\n",
    "    plt.annotate('two-handed\\npractice', \n",
    "                 xy=(session_number, bar_height),  # Arrow tip (session 8 bar)\n",
    "                 xytext=(session_number, bar_height + 15),  # Text position above the bar\n",
    "                 arrowprops=dict(facecolor='black', arrowstyle='->'),  # Arrow pointing upwards\n",
    "                 rotation=90,  # Rotate text 90 degrees to the left\n",
    "                 ha='center',  # Center horizontally\n",
    "                 va='bottom',  # Align text to the bottom vertically\n",
    "                 fontsize=14)  # Font size for the annotation\n",
    "\n",
    "# Add an arrow for session 10 with text \"irregular pattern with off beat and reversal\"\n",
    "session_number = 10\n",
    "if session_number in sorted_sessions:\n",
    "    index_of_session_10 = sorted_sessions.index(session_number)\n",
    "    bar_height = sorted_average_accuracies[index_of_session_10]\n",
    "    plt.annotate('off beat\\nand reversal', \n",
    "                 xy=(session_number, bar_height),  # Arrow tip (session 10 bar)\n",
    "                 xytext=(session_number, bar_height + 15),  # Text position above the bar\n",
    "                 arrowprops=dict(facecolor='black', arrowstyle='->'),  # Arrow pointing upwards\n",
    "                 rotation=90,  # Rotate text 90 degrees to the left\n",
    "                 ha='center',  # Center horizontally\n",
    "                 va='bottom',  # Align text to the bottom vertically\n",
    "                 fontsize=14)  # Font size for the annotation\n",
    "\n",
    "# Add an arrow for session 14 with text \"paradiddle and reversal learning\"\n",
    "session_number = 14\n",
    "if session_number in sorted_sessions:\n",
    "    index_of_session_14 = sorted_sessions.index(session_number)\n",
    "    bar_height = sorted_average_accuracies[index_of_session_14]\n",
    "    plt.annotate('paradiddle', \n",
    "                 xy=(session_number, bar_height),  # Arrow tip (session 14 bar)\n",
    "                 xytext=(session_number, bar_height + 15),  # Text position above the bar\n",
    "                 arrowprops=dict(facecolor='black', arrowstyle='->'),  # Arrow pointing upwards\n",
    "                 rotation=90,  # Rotate text 90 degrees to the left\n",
    "                 ha='center',  # Center horizontally\n",
    "                 va='bottom',  # Align text to the bottom vertically\n",
    "                 fontsize=14)  # Font size for the annotation\n",
    "\n",
    "# Save the plot\n",
    "plt.savefig(os.path.join(figdir, 'average_hit_accuracy_per_session.png'), bbox_inches='tight')\n",
    "plt.savefig(os.path.join(figdir, 'average_hit_accuracy_per_session.pdf'), bbox_inches='tight')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba51b4c-ccc9-44e8-bcb2-0740a97775ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import linregress\n",
    "import numpy as np\n",
    "\n",
    "# Convert lists to numpy arrays if they're not already\n",
    "sorted_average_accuracies = np.array(sorted_average_accuracies)\n",
    "fail_counts = np.array(fail_counts)\n",
    "\n",
    "# Remove positions where both arrays have zeros\n",
    "mask = ~((sorted_average_accuracies == 0) & (fail_counts == 0))\n",
    "sorted_average_accuracies = sorted_average_accuracies[mask]\n",
    "fail_counts = fail_counts[mask]\n",
    "\n",
    "# Scatter plot\n",
    "plt.scatter(sorted_average_accuracies, fail_counts, color='k',marker='x')\n",
    "plt.xlabel('Average Hit Accuracy (%)')\n",
    "plt.ylabel('Number of Participants who gave up')\n",
    "\n",
    "# Linear regression\n",
    "slope, intercept, r_value, p_value, std_err = linregress(sorted_average_accuracies, fail_counts)\n",
    "\n",
    "# Plot the regression line\n",
    "plt.plot(sorted_average_accuracies, intercept + slope * sorted_average_accuracies, 'r', label=f'Linear fit, R = {r_value:.2f}, p = {p_value:.4f}')\n",
    "plt.legend()\n",
    "\n",
    "plt.title(cohort + ' participants')\n",
    "\n",
    "# Save the plot\n",
    "plt.savefig(os.path.join(figdir, 'give_up_vs_hit_accuracy.png'), bbox_inches='tight', dpi=300)\n",
    "plt.savefig(os.path.join(figdir, 'give_up_vs_hit_accuracy.pdf'), bbox_inches='tight')\n",
    "\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n",
    "\n",
    "# Print the calculated r value and p-value\n",
    "print(f'R value: {r_value}')\n",
    "print(f'P value: {p_value}')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8363451-5ecb-4f61-a30f-b3f5530f640a",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e2d719-3eac-4a2d-a559-cb741dbec89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# Number of subplots\n",
    "num_plots = len(participants)\n",
    "\n",
    "# Determine the size of the subplot grid (square-ish)\n",
    "grid_size = int(math.ceil(math.sqrt(num_plots)))\n",
    "\n",
    "# Create subplots\n",
    "fig, axes = plt.subplots(grid_size, grid_size * 2, figsize=(15, 10))  # Two columns per participant\n",
    "\n",
    "# Flatten axes array for easy iteration\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Determine consistent axis limits for the accuracy plots\n",
    "all_left_accuracies = []\n",
    "all_right_accuracies = []\n",
    "\n",
    "# First pass: collect all accuracy data\n",
    "for participant in participants:\n",
    "    # Filter metadata for the current participant\n",
    "    participant_metadata = {key: value for key, value in metadata.items() if key[0] == participant}\n",
    "    \n",
    "    if participant_metadata:\n",
    "        left_accuracies = [float(meta.get('Left Accuracy (%)', 0)) for (pid, session, attempt), meta in participant_metadata.items()]\n",
    "        right_accuracies = [float(meta.get('Right Accuracy (%)', 0)) for (pid, session, attempt), meta in participant_metadata.items()]\n",
    "        \n",
    "        all_left_accuracies.extend(left_accuracies)\n",
    "        all_right_accuracies.extend(right_accuracies)\n",
    "\n",
    "max_left_accuracy = max(all_left_accuracies, default=100)\n",
    "max_right_accuracy = max(all_right_accuracies, default=100)\n",
    "\n",
    "# Second pass: plot data\n",
    "for i, participant in enumerate(participants):\n",
    "    # Filter metadata for the current participant\n",
    "    participant_metadata = {key: value for key, value in metadata.items() if key[0] == participant}\n",
    "    \n",
    "    if not participant_metadata:\n",
    "        # If no metadata for the participant, skip this subplot\n",
    "        axes[2 * i].axis('off')\n",
    "        axes[2 * i + 1].axis('off')\n",
    "        continue\n",
    "    \n",
    "    # Extract accuracies\n",
    "    left_accuracies = [float(meta.get('Left Accuracy (%)', 0)) for (pid, session, attempt), meta in participant_metadata.items()]\n",
    "    right_accuracies = [float(meta.get('Right Accuracy (%)', 0)) for (pid, session, attempt), meta in participant_metadata.items()]\n",
    "    \n",
    "    # Plot Left Accuracy\n",
    "    ax_left = axes[2 * i]\n",
    "    ax_left.plot(left_accuracies, marker='o', linestyle='-', color='b')\n",
    "    ax_left.set_title(f'{participant} - Left Accuracy')\n",
    "    ax_left.set_xlabel('Attempt Number')\n",
    "    ax_left.set_ylabel('Left Accuracy (%)')\n",
    "    ax_left.set_ylim(0, max_left_accuracy)\n",
    "    ax_left.grid(True)\n",
    "    \n",
    "    # Plot Right Accuracy\n",
    "    ax_right = axes[2 * i + 1]\n",
    "    ax_right.plot(right_accuracies, marker='o', linestyle='-', color='r')\n",
    "    ax_right.set_title(f'{participant} - Right Accuracy')\n",
    "    ax_right.set_xlabel('Attempt Number')\n",
    "    ax_right.set_ylabel('Right Accuracy (%)')\n",
    "    ax_right.set_ylim(0, max_right_accuracy)\n",
    "    ax_right.grid(True)\n",
    "\n",
    "# Hide any unused subplots\n",
    "for j in range(num_plots * 2, len(axes)):\n",
    "    axes[j].axis('off')\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(os.path.join(figdir, 'left_and_right_hits.png'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16ebd1f-8dd9-4a7c-8226-9b91386e8b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# Number of subplots\n",
    "num_plots = len(participants)\n",
    "\n",
    "# Determine the size of the subplot grid (square-ish)\n",
    "grid_size = int(math.ceil(math.sqrt(num_plots)))\n",
    "\n",
    "# Create subplots\n",
    "fig, axes = plt.subplots(grid_size, grid_size * 2, figsize=(15, 10))  # Two columns per participant\n",
    "\n",
    "# Flatten axes array for easy iteration\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Determine consistent axis limits for the accuracy plots\n",
    "all_left_accuracies = []\n",
    "all_right_accuracies = []\n",
    "\n",
    "# Collect all accuracy data and session boundaries\n",
    "session_boundaries = {}\n",
    "\n",
    "for participant in participants:\n",
    "    # Filter metadata for the current participant\n",
    "    participant_metadata = {key: value for key, value in metadata.items() if key[0] == participant}\n",
    "    \n",
    "    if participant_metadata:\n",
    "        left_accuracies = [float(meta.get('Left Accuracy (%)', 0)) for (pid, session, attempt), meta in participant_metadata.items()]\n",
    "        right_accuracies = [float(meta.get('Right Accuracy (%)', 0)) for (pid, session, attempt), meta in participant_metadata.items()]\n",
    "        \n",
    "        all_left_accuracies.extend(left_accuracies)\n",
    "        all_right_accuracies.extend(right_accuracies)\n",
    "\n",
    "        # Track session boundaries\n",
    "        sorted_attempts = sorted((attempt for (pid, session, attempt), _ in participant_metadata.items()))\n",
    "        for session in sorted(set(session for (_, session, _) in participant_metadata.keys())):\n",
    "            session_boundaries[(participant, session)] = [sorted_attempts.index(min(attempt for (_, s, attempt) in participant_metadata.keys() if s == session)),\n",
    "                                                          sorted_attempts.index(max(attempt for (_, s, attempt) in participant_metadata.keys() if s == session))]\n",
    "\n",
    "max_left_accuracy = max(all_left_accuracies, default=100)\n",
    "max_right_accuracy = max(all_right_accuracies, default=100)\n",
    "\n",
    "# Plot data with shading\n",
    "for i, participant in enumerate(participants):\n",
    "    # Filter metadata for the current participant\n",
    "    participant_metadata = {key: value for key, value in metadata.items() if key[0] == participant}\n",
    "    \n",
    "    if not participant_metadata:\n",
    "        # If no metadata for the participant, skip this subplot\n",
    "        axes[2 * i].axis('off')\n",
    "        axes[2 * i + 1].axis('off')\n",
    "        continue\n",
    "    \n",
    "    # Extract accuracies and attempts\n",
    "    attempts_and_left_accuracies = [(attempt, float(meta.get('Left Accuracy (%)', 0))) for (pid, session, attempt), meta in participant_metadata.items()]\n",
    "    attempts_and_right_accuracies = [(attempt, float(meta.get('Right Accuracy (%)', 0))) for (pid, session, attempt), meta in participant_metadata.items()]\n",
    "\n",
    "    # Sort by attempts\n",
    "    attempts_and_left_accuracies.sort()\n",
    "    attempts_and_right_accuracies.sort()\n",
    "\n",
    "    attempts_left, left_accuracies = zip(*attempts_and_left_accuracies)\n",
    "    attempts_right, right_accuracies = zip(*attempts_and_right_accuracies)\n",
    "    \n",
    "    # Plot Left Accuracy\n",
    "    ax_left = axes[2 * i]\n",
    "    ax_left.plot(attempts_left, left_accuracies, marker='o', linestyle='-', color='b')\n",
    "    \n",
    "    # Shade regions based on sessions\n",
    "    for (part, session), (start, end) in session_boundaries.items():\n",
    "        if part == participant:\n",
    "            ax_left.axvspan(attempts_left[start], attempts_left[end], color='gray', alpha=0.3, label=f'Session {session}')\n",
    "    \n",
    "    ax_left.set_title(f'{participant[:5]} - Left Accuracy')\n",
    "    ax_left.set_xlabel('Attempt Number')\n",
    "    ax_left.set_ylabel('Left Accuracy (%)')\n",
    "    ax_left.set_ylim(0, max_left_accuracy)\n",
    "    ax_left.grid(True)\n",
    "    #ax_left.legend(loc='upper right')\n",
    "    \n",
    "    # Plot Right Accuracy\n",
    "    ax_right = axes[2 * i + 1]\n",
    "    ax_right.plot(attempts_right, right_accuracies, marker='o', linestyle='-', color='r')\n",
    "    \n",
    "    # Shade regions based on sessions\n",
    "    for (part, session), (start, end) in session_boundaries.items():\n",
    "        if part == participant:\n",
    "            ax_right.axvspan(attempts_right[start], attempts_right[end], color='gray', alpha=0.3, label=f'Session {session}')\n",
    "    \n",
    "    ax_right.set_title(f'{participant[:5]} - Right Accuracy')\n",
    "    ax_right.set_xlabel('Attempt Number')\n",
    "    ax_right.set_ylabel('Right Accuracy (%)')\n",
    "    ax_right.set_ylim(0, max_right_accuracy)\n",
    "    ax_right.grid(True)\n",
    "    #ax_right.legend(loc='upper right')\n",
    "\n",
    "# Hide any unused subplots\n",
    "for j in range(num_plots * 2, len(axes)):\n",
    "    axes[j].axis('off')\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab7fd0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(fulldata_table[(participants[i], this_session_number, this_attempt_number)][])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8785aad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO - calculate the number of double taps etc.\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#2 3 5 6 8 9\n",
    "#i = 4\n",
    "#for i in [0, 1, 4, 7, 10]:\n",
    "# Convert columns to numpy arrays for easier manipulation\n",
    "# expected_hits = np.array(data_table['Expected Right hit (t0)'])\n",
    "expected_hits = np.array(fulldata_table[(participants[i], this_session_number, this_attempt_number)]['Expected Right hit (t0)'])\n",
    "\n",
    "# actual_hits = np.array(data_table['Patient Right hit detected'])\n",
    "actual_hits = np.array(fulldata_table[(participants[i], this_session_number, this_attempt_number)]['Patient Right hit detected'])\n",
    "\n",
    "# window_regions = np.array(data_table['Expected Right hit window region'])\n",
    "window_regions = np.array(fulldata_table[(participants[i], this_session_number, this_attempt_number)]['Expected Right hit window region'])\n",
    "\n",
    "\n",
    "#subset = expected_hits[:100]\n",
    "\n",
    "#plt.figure(figsize=(10, 4))\n",
    "#plt.plot(subset, marker='o')\n",
    "\n",
    "plt.plot(expected_hits, \".\", color = \"r\") #[2500:2510]\n",
    "plt.plot(actual_hits, \".\", color = \"b\") #[2500:2510]\n",
    "plt.plot(window_regions, \".\", color = \"g\") #[2500:2510]\n",
    "\n",
    "\n",
    "# Initialize lists to store timing accuracy, successful hits, and double taps\n",
    "hit_accuracy = []\n",
    "successful_hits = 0\n",
    "total_expected_hits = np.sum(expected_hits)\n",
    "double_taps = 0\n",
    "\n",
    "# Function to find contiguous regions of 1's\n",
    "def find_contiguous_regions(data):\n",
    "    regions = []\n",
    "    start = None\n",
    "    for i, val in enumerate(data):\n",
    "        if val == 1 and start is None:\n",
    "            start = i\n",
    "        elif val == 0 and start is not None:\n",
    "            regions.append((start, i - 1))\n",
    "            start = None\n",
    "    if start is not None:\n",
    "        regions.append((start, len(data) - 1))\n",
    "    return regions\n",
    "\n",
    "# Find all contiguous regions of 1's in the window region\n",
    "windows = find_contiguous_regions(window_regions)\n",
    "\n",
    "# Iterate over the windows\n",
    "for start, end in windows:\n",
    "    # Find the indices of expected hits within this window\n",
    "    expected_indices = np.where(expected_hits[start:end+1] == 1)[0] + start\n",
    "    # Find the indices of actual hits within this window\n",
    "    actual_indices = np.where(actual_hits[start:end+1] == 1)[0] + start\n",
    "    \n",
    "    if len(expected_indices) > 0:\n",
    "        # If there are actual hits, record the timing accuracy for each expected hit\n",
    "        for expected_index in expected_indices:\n",
    "            # Find actual hits within this window\n",
    "            actual_hits_in_window = [index for index in actual_indices if start <= index <= end]\n",
    "            if len(actual_hits_in_window) == 0:\n",
    "                # If no actual hit in the window, append NaN\n",
    "                hit_accuracy.append(np.nan)\n",
    "            else:\n",
    "                # Calculate the timing accuracy (absolute value) for each actual hit\n",
    "                for actual_index in actual_hits_in_window:\n",
    "                    timing_accuracy = actual_index - expected_index\n",
    "                    hit_accuracy.append(timing_accuracy)\n",
    "                    successful_hits += 1\n",
    "                    # Check for double taps: if there is more than one actual hit in the window\n",
    "                    if len(actual_hits_in_window) > 1:\n",
    "                        double_taps += 1\n",
    "\n",
    "# Convert the hit accuracy list to a pandas Series (or array if preferred)\n",
    "hit_accuracy = pd.Series(hit_accuracy)\n",
    "\n",
    "# Calculate the success rate\n",
    "success_rate = successful_hits / total_expected_hits if total_expected_hits > 0 else 0\n",
    "\n",
    "#deleted the max to work with the min and the max, but it shouldn't matter \n",
    "\n",
    "# Print the results\n",
    "print(\"Timing accuracy:\", hit_accuracy.max())\n",
    "print(\"Number of successful hits:\", successful_hits)\n",
    "print(\"Number of double taps:\", double_taps)\n",
    "print(\"Number of double taps rate:\", double_taps/successful_hits*success_rate)\n",
    "\n",
    "print(\"Total expected hits:\", total_expected_hits)\n",
    "print(\"Success rate single tap:\", (1-double_taps/successful_hits)*success_rate)\n",
    "print(success_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09194ae2",
   "metadata": {},
   "source": [
    "I have the successful_hits and the ratio between double taps and that should be the number of double taps\n",
    "\n",
    "Then I have succesfull_rate_onetap = (1-ratiodouble)*successrate\n",
    "\n",
    "sucessful_rate_doubletap = ratiodouble*successrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebb539d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(hit_accuracy,bins=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495898e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(actual_hits,type(actual_hits), actual_hits.shape)\n",
    "print(expected_hits,type(expected_hits), expected_hits.shape)\n",
    "print(window_regions,type(window_regions), window_regions.shape)\n",
    "\n",
    "fulldata_table[(participant, this_session_number, this_attempt_number)]['Expected Left hit (t0)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8011e18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fulldata_table.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b307e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fulldata_table[(participant, this_session_number, this_attempt_number)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc02a77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"CORRECT CODE\"\"\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "keys_to_use = fulldata_table.keys()\n",
    "\n",
    "def find_contiguous_regions(data):\n",
    "    regions = []\n",
    "    start = None\n",
    "    for i, val in enumerate(data):\n",
    "        if val == 1 and start is None:\n",
    "            start = i\n",
    "        elif val == 0 and start is not None:\n",
    "            regions.append((start, i - 1))\n",
    "            start = None\n",
    "    if start is not None:\n",
    "        regions.append((start, len(data) - 1))\n",
    "    return regions\n",
    "\n",
    "all_hit_accuracies = []\n",
    "\n",
    "for pid, session, attempt in keys_to_use:\n",
    "    df = fulldata_table[(pid, session, attempt)]\n",
    "\n",
    "    expected_hits = np.array(df['Expected Right hit (t0)'])\n",
    "    actual_hits = np.array(df['Patient Right hit detected'])\n",
    "    window_regions = np.array(df['Expected Right hit window region'])\n",
    "\n",
    "    windows = find_contiguous_regions(window_regions)\n",
    "    hit_accuracy = []\n",
    "\n",
    "    for start, end in windows:\n",
    "        expected_indices = np.where(expected_hits[start:end+1] == 1)[0] + start\n",
    "        actual_indices = np.where(actual_hits[start:end+1] == 1)[0] + start\n",
    "\n",
    "        for expected_index in expected_indices:\n",
    "            actual_hits_in_window = [idx for idx in actual_indices if start <= idx <= end]\n",
    "            if not actual_hits_in_window:\n",
    "                hit_accuracy.append(np.nan)\n",
    "            else:\n",
    "                for actual_index in actual_hits_in_window:\n",
    "                    hit_accuracy.append(actual_index - expected_index)\n",
    "\n",
    "    all_hit_accuracies.extend(hit_accuracy)\n",
    "\n",
    "#TODO add the double tap from joe here\n",
    "\"\"\"\n",
    "for start, end in windows:\n",
    "    # Find the indices of expected hits within this window\n",
    "    expected_indices = np.where(expected_hits[start:end+1] == 1)[0] + start\n",
    "    # Find the indices of actual hits within this window\n",
    "    actual_indices = np.where(actual_hits[start:end+1] == 1)[0] + start\n",
    "    \n",
    "    if len(expected_indices) > 0:\n",
    "        # If there are actual hits, record the timing accuracy for each expected hit\n",
    "        for expected_index in expected_indices:\n",
    "            # Find actual hits within this window\n",
    "            actual_hits_in_window = [index for index in actual_indices if start <= index <= end]\n",
    "            if len(actual_hits_in_window) == 0:\n",
    "                # If no actual hit in the window, append NaN\n",
    "                hit_accuracy.append(np.nan)\n",
    "            else:\n",
    "                # Calculate the timing accuracy (absolute value) for each actual hit\n",
    "                for actual_index in actual_hits_in_window:\n",
    "                    timing_accuracy = actual_index - expected_index\n",
    "                    hit_accuracy.append(timing_accuracy)\n",
    "                    successful_hits += 1\n",
    "                    # Check for double taps: if there is more than one actual hit in the window\n",
    "                    if len(actual_hits_in_window) > 1:\n",
    "                        double_taps += 1\n",
    "\"\"\"\n",
    "\n",
    "hit_accuracy_series = pd.Series(all_hit_accuracies).dropna()\n",
    "df['Delays Right Hand'] = hit_accuracy_series\n",
    "#print(df['Delays Right Hand'])\n",
    "#print(df.keys)\n",
    "\n",
    "mean_accuracy = hit_accuracy_series.mean()\n",
    "std_accuracy = hit_accuracy_series.std()\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.hist(hit_accuracy_series, bins=30, edgecolor='black', alpha=0.7)\n",
    "plt.axvline(mean_accuracy, color='red', linestyle='dashed', linewidth=1, label=f\"Mean = {mean_accuracy:.2f}\")\n",
    "plt.axvline(mean_accuracy + std_accuracy, color='green', linestyle='dotted', linewidth=1, label=f\"+1 = {mean_accuracy + std_accuracy:.2f}\")\n",
    "plt.axvline(mean_accuracy - std_accuracy, color='green', linestyle='dotted', linewidth=1, label=f\"-1 = {mean_accuracy - std_accuracy:.2f}\")\n",
    "plt.title('Right Hand Hits')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Counts')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Show accuracy statistics?\n",
    "print(f\"Mean: {mean_accuracy:.2f}\")\n",
    "print(f\"sd: {std_accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f090dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"CORRECT CODE\"\"\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "keys_to_use = fulldata_table.keys()\n",
    "\n",
    "def find_contiguous_regions(data):\n",
    "    regions = []\n",
    "    start = None\n",
    "    for i, val in enumerate(data):\n",
    "        if val == 1 and start is None:\n",
    "            start = i\n",
    "        elif val == 0 and start is not None:\n",
    "            regions.append((start, i - 1))\n",
    "            start = None\n",
    "    if start is not None:\n",
    "        regions.append((start, len(data) - 1))\n",
    "    return regions\n",
    "\n",
    "all_hit_accuracies = []\n",
    "\n",
    "for pid, session, attempt in keys_to_use:\n",
    "    df = fulldata_table[(pid, session, attempt)]\n",
    "\n",
    "    expected_hits = np.array(df['Expected Left hit (t0)'])\n",
    "    actual_hits = np.array(df['Patient Left hit detected'])\n",
    "    window_regions = np.array(df['Expected Left hit window region'])\n",
    "\n",
    "    windows = find_contiguous_regions(window_regions)\n",
    "    hit_accuracy = []\n",
    "\n",
    "    for start, end in windows:\n",
    "        expected_indices = np.where(expected_hits[start:end+1] == 1)[0] + start\n",
    "        actual_indices = np.where(actual_hits[start:end+1] == 1)[0] + start\n",
    "\n",
    "        for expected_index in expected_indices:\n",
    "            actual_hits_in_window = [idx for idx in actual_indices if start <= idx <= end]\n",
    "            if not actual_hits_in_window:\n",
    "                hit_accuracy.append(np.nan)\n",
    "            else:\n",
    "                for actual_index in actual_hits_in_window:\n",
    "                    hit_accuracy.append(actual_index - expected_index)\n",
    "\n",
    "    all_hit_accuracies.extend(hit_accuracy)\n",
    "\n",
    "hit_accuracy_series = pd.Series(all_hit_accuracies).dropna()\n",
    "df['Delays Left Hand'] = hit_accuracy_series\n",
    "\n",
    "\n",
    "mean_accuracy = hit_accuracy_series.mean()\n",
    "std_accuracy = hit_accuracy_series.std()\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.hist(hit_accuracy_series, bins=40, edgecolor='black', alpha=0.7)\n",
    "plt.axvline(mean_accuracy, color='red', linestyle='dashed', linewidth=1, label=f\"Mean = {mean_accuracy:.2f}\")\n",
    "plt.axvline(mean_accuracy + std_accuracy, color='green', linestyle='dotted', linewidth=1, label=f\"+1 = {mean_accuracy + std_accuracy:.2f}\")\n",
    "plt.axvline(mean_accuracy - std_accuracy, color='green', linestyle='dotted', linewidth=1, label=f\"-1 = {mean_accuracy - std_accuracy:.2f}\")\n",
    "plt.title('Left hand Hits')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Counts')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Show accuracy statistics?\n",
    "print(f\"Mean: {mean_accuracy:.2f}\")\n",
    "print(f\"sd: {std_accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb590f8a",
   "metadata": {},
   "source": [
    "Can we check the information and see in the cases that they are really late the hit how many times they have missed?\n",
    "Is there a correlation between a larger delay time and the number of times that person has missed?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af19832",
   "metadata": {},
   "source": [
    "To the dataframe that I have I want to add the delay time as an extra column\n",
    "Then work for the same frame in a correlation between accuracy and absolute delay time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b69d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_right = df.loc[:, 'Delays Right Hand'].mean()\n",
    "sigma_right = df.loc[:, 'Delays Right Hand'].std()\n",
    "\n",
    "\n",
    "#df.loc[:, 'Delays Right Hand'].mean()\n",
    "s_right = np.random.normal(mu_right, sigma_right, 1000)\n",
    "\n",
    "\n",
    "mu_left = df.loc[:, 'Delays Left Hand'].mean()\n",
    "sigma_left = df.loc[:, 'Delays Left Hand'].std()\n",
    "\n",
    "print(len(fulldata_table[(participant, this_session_number, this_attempt_number)]['Expected Left hit (t0)']))\n",
    "X_L = np.sum(fulldata_table[(participant, this_session_number, this_attempt_number)]['Expected Left hit (t0)'] == 1)\n",
    "X_R = np.sum(fulldata_table[(participant, this_session_number, this_attempt_number)]['Expected Right hit (t0)'] == 1)\n",
    "#df.loc[:, 'Delays Right Hand'].mean()\n",
    "s_right = np.random.normal(mu_right, sigma_right, X_R)\n",
    "s_left = np.random.normal(mu_left, sigma_left, X_L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6cdb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "count, bins, ignored = plt.hist(s_right, 30, density=True)\n",
    "plt.plot(bins, 1/(sigma_right * np.sqrt(2 * np.pi)) *\n",
    "               np.exp( - (bins - mu_right)**2 / (2 * sigma_right**2) ),\n",
    "         linewidth=2, color='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2385c6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "count, bins, ignored = plt.hist(s_right, 30, density=True)\n",
    "plt.plot(bins, 1/(sigma_left * np.sqrt(2 * np.pi)) *\n",
    "               np.exp( - (bins - mu_left)**2 / (2 * sigma_left**2) ),\n",
    "         linewidth=2, color='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da39344",
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "\"\"\"HERE\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7ef9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(actual_hits,type(actual_hits), actual_hits.shape)\n",
    "print(expected_hits,type(expected_hits), expected_hits.shape)\n",
    "print(window_regions,type(window_regions), window_regions.shape)\n",
    "\n",
    "fulldata_table[(participant, this_session_number, this_attempt_number)] #['Expected Left hit (t0)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88c94f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic_df = pd.DataFrame({\n",
    "    'Expected Left hit (t0)': fulldata_table[(participant, this_session_number, this_attempt_number)]['Expected Left hit (t0)'],\n",
    "    'Expected Right hit (t0)':fulldata_table[(participant, this_session_number, this_attempt_number)]['Expected Right hit (t0)'],\n",
    "    'Patient Left hit detected':fulldata_table[(participant, this_session_number, this_attempt_number)]['Patient Left hit detected'],\n",
    "    'Patient Right hit detected':fulldata_table[(participant, this_session_number, this_attempt_number)]['Patient Right hit detected'],\n",
    "    'Delays Right Hand': 0,\n",
    "    'Delays Left Hand': 0\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901409d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "synthetic_df['Patient Left hit detected'] = 0\n",
    "synthetic_df['Patient Right hit detected'] = 0\n",
    "\n",
    "# Find expected hit indices\n",
    "expected_left_indices = synthetic_df.index[synthetic_df['Expected Left hit (t0)'] == 1].to_numpy()\n",
    "expected_right_indices = synthetic_df.index[synthetic_df['Expected Right hit (t0)'] == 1].to_numpy()\n",
    "\n",
    "# Convert delay from ms to index offset (assuming 50 ms per row)\n",
    "left_offsets = np.round(s_left).astype(int)\n",
    "right_offsets = np.round(s_right).astype(int)\n",
    "\n",
    "# Apply delays: compute target indices\n",
    "left_hit_indices = expected_left_indices + left_offsets\n",
    "right_hit_indices = expected_right_indices + right_offsets\n",
    "\n",
    "# Remove out-of-bound indices\n",
    "left_hit_indices = left_hit_indices[left_hit_indices < len(synthetic_df)]\n",
    "right_hit_indices = right_hit_indices[right_hit_indices < len(synthetic_df)]\n",
    "\n",
    "# Set simulated hits\n",
    "synthetic_df.loc[left_hit_indices, 'Patient Left hit detected'] = 1\n",
    "synthetic_df.loc[right_hit_indices, 'Patient Right hit detected'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c1d9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missed hits and hits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6292c2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mismatches_left = synthetic_df[\n",
    "    (synthetic_df['Expected Left hit (t0)'] == 1) &\n",
    "    (synthetic_df['Patient Left hit detected'] == 0)\n",
    "]\n",
    "\n",
    "# Print the first mismatch, if any\n",
    "if not mismatches_left.empty:\n",
    "    print(\"First mismatch (Left Hand):\")\n",
    "    print(mismatches_left.head(1))\n",
    "else:\n",
    "    print(\"No mismatches found for Left Hand.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fba5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(synthetic_df.iloc[1490:1500])\n",
    "hits1 = synthetic_df[synthetic_df['Expected Right hit (t0)'] == 1]\n",
    "print(synthetic_df.iloc[1625:1635])\n",
    "#print(hits1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f14321",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(synthetic_df['Delays Right Hand'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0eeed5",
   "metadata": {},
   "source": [
    "To the dataframe we need to add:\n",
    "\n",
    "- Time\n",
    "- Expected tap right\n",
    "- Expected tap left\n",
    "- Actual tap righ\n",
    "- Actual tap left\n",
    "- Delays ??\n",
    "- For each patient separately only one track"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d6ce52",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b994a073",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
